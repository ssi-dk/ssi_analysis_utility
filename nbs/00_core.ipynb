{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp core\n",
    "# This will create a package named ssi_analysis_utility/core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "import nbdev\n",
    "from nbdev.showdoc import *  # ignore this Pylance warning in favor of following nbdev docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For help with the Markdown language, see [this guide](https://www.markdownguide.org/basic-syntax/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global static vars\n",
    "These are used to modify the template for individual use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# Need the ssi_analysis_utility for a few functions, this can be considered a static var\n",
    "\n",
    "import importlib\n",
    "import importlib.util\n",
    "import os\n",
    "\n",
    "PACKAGE_NAME: str = (\n",
    "    \"ssi_analysis_utility\"  # Make sure to adjust this to your package name\n",
    ")\n",
    "DEV_MODE: bool = (\n",
    "    False  # set below to override, as this is in an export block it'll be exported while the dev mode section is not\n",
    ")\n",
    "\n",
    "PACKAGE_DIR = None\n",
    "try:\n",
    "    spec = importlib.util.find_spec(PACKAGE_NAME)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    PACKAGE_DIR = os.path.dirname(module.__file__)\n",
    "except ImportError:\n",
    "    DEV_MODE = True\n",
    "except AttributeError:\n",
    "    DEV_MODE = True\n",
    "PROJECT_DIR = os.getcwd()  # override value in dev mode\n",
    "if PROJECT_DIR.endswith('nbs'):\n",
    "    DEV_MODE=True\n",
    "    PROJECT_DIR=os.path.split(PROJECT_DIR)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev mode\n",
    "If you're developing this versus running this, you'll have access to slightly different things. Notable the nbdev functions are only for development and not for runtime. This matters for items such as the config. So we need to detect if you are in dev mode or not and the code has to adjust accordingly. Notice that this section is not exported so will only work in the notebook and not in the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section uses nbdev functions so should not be exported as it's for dev purposes\n",
    "import os\n",
    "\n",
    "if DEV_MODE:\n",
    "    PACKAGE_DIR = nbdev.config.get_config(cfg_name=\"settings.ini\", path=os.getcwd())[\n",
    "        \"lib_path\"\n",
    "    ]  # the library is the package of course\n",
    "    PROJECT_DIR = nbdev.config.get_config(\n",
    "        cfg_name=\"settings.ini\", path=os.getcwd()\n",
    "    ).config_path  # the default location of nbdev config file (settings.ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    " A module which contains common functions to be used by other modules. Those that exist in the template are meant to be common functions we can use against multiple packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#|hide\n",
    "\n",
    "Notebook blocks starting with #|hide are not shown in the documentation and not exported to the python package. Blocks with #|export are exported to the python package. Blocks with neither are shown to the documentation but not exported to the python package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "Currently all libraries included are listed at the top and calls to them are also made in the block of code that uses them. This is for readability and the performance hit of the import is negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# standard libs\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Common to template\n",
    "# add into settings.ini, requirements, package name is python-dotenv, for conda build ensure `conda config --add channels conda-forge`\n",
    "import dotenv  # for loading config from .env files, https://pypi.org/project/python-dotenv/\n",
    "import envyaml  # Allows to loads env vars into a yaml file, https://github.com/thesimj/envyaml\n",
    "import fastcore  # To add functionality related to nbdev development, https://github.com/fastai/fastcore/\n",
    "import pandas  # For sample sheet manipulation\n",
    "from fastcore import (\n",
    "    test,\n",
    ")\n",
    "from fastcore.script import (\n",
    "    call_parse,\n",
    ")  # for @call_parse, https://fastcore.fast.ai/script\n",
    "\n",
    "# Project specific libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "Our config file holds all program and user specific variables. This is a good practice to follow as it allows us to easily change variables without having to change code. It also allows us to easily change variables based on the environment we are running in. For example, we may want to run a program in a test environment with a different database than we would in production. This is also a good practice to follow as it allows us to easily change variables without having to change code. It also allows us to easily change variables based on the environment we are running in. For example, we may want to run a program in a test environment with a different database than we would in production.\n",
    "\n",
    "Configuration is templated to rely on environment (ENV) variables. A default ENV config is provided in `./config/config.default.env` and more advanced data structures are supported in `./config/config.default.yaml`. The `.yaml` file is meant to represent what your program actually works with and the `.env` file options the user can change at run time.\n",
    "\n",
    "Make sure you know the priority of variables and check on them when debugging your code. Also ensure that your yaml file is referenced appropriately in the `.env` file. \n",
    "\n",
    "When in use there's an expectation you'll have multiple config files for different use cases e.g. development, production environment for different paths, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set env variables\n",
    "A helper function for getting your config values, this will set the environment variables with the provided `.env` values. If you're missing values it'll ensure they're loaded in with the defaults file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import importlib\n",
    "import importlib.util\n",
    "\n",
    "\n",
    "def set_env_variables(config_path: str, overide_env_vars: bool = True) -> bool:\n",
    "    # Load dot env sets environmental values from a file, if the value already exists it will not be overwritten unless override is set to True.\n",
    "    # If we have multiple .env files then we need to apply the one which we want to take precedence last with overide.\n",
    "\n",
    "    # Order of precedence: .env file > environment variables > default values\n",
    "    # When developing, making a change to the config will not be reflected until the environment is restarted\n",
    "\n",
    "    # Set the env vars first, this is needed for the card.yaml to replace ENV variables\n",
    "    # NOTE: You need to adjust PROJECT_NAME to your package name for this to work, the exception is only for dev purposes\n",
    "    # This here checks if your package is installed, such as through pypi or through pip install -e  [.dev] for development. If it is then it'll go there and use the config files there as your default values.\n",
    "    try:\n",
    "        dotenv.load_dotenv(\n",
    "            f\"{PACKAGE_DIR}/config/config.default.env\", override=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {PACKAGE_DIR}/config/config.default.env does not exist\")\n",
    "        return False\n",
    "\n",
    "    # 2. set values from file:\n",
    "    if os.path.isfile(config_path):\n",
    "        dotenv.load_dotenv(config_path, override=overide_env_vars)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get config\n",
    "\n",
    "When you run this function, assuming things are set up properly, you end up with a dict that matches your `.yaml` file. This file will have all the inputs for the package and settings of your program.\n",
    "\n",
    "To do this it will use a `.env` config file, which has an associated yaml file defined with `CORE_YAML_CONFIG_FILE` in the `.env` file. And then use the `.env` file to load values into the associated `.yaml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import importlib\n",
    "import importlib.util\n",
    "\n",
    "\n",
    "def get_config(config_path: str = None, overide_env_vars: bool = True) -> dict:\n",
    "    if config_path is None:\n",
    "        config_path = \"\"\n",
    "    # First sets environment with variables from config_path, then uses those variables to fill in appropriate values in the config.yaml file, the yaml file is then returned as a dict\n",
    "    # If you want user env variables to take precedence over the config.yaml file then set overide_env_vars to False\n",
    "    set_env_variables(config_path, overide_env_vars)\n",
    "   \n",
    "    config: dict = envyaml.EnvYAML(\n",
    "        os.environ.get(\n",
    "            \"CORE_YAML_CONFIG_FILE\", f\"{PACKAGE_DIR}/config/config.default.yaml\"\n",
    "        ),\n",
    "        strict=False,\n",
    "    ).export()\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "All the user input variables and machine adjustable variables should be in your config, which is a dict. Reference config.default.yaml for how to access your variables. Also note that with python dicts you can use `dict_variable.get(\"variable\", default_value)` to ensure that you don't get a key error if the variable is not set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# create a os.PathLike object\n",
    "config = get_config(os.environ.get(\"CORE_CONFIG_FILE\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show project env vars\n",
    "A helper function intended to only be used with debugging. It shows all your project specific environmental variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def show_project_env_vars(config: dict) -> None:\n",
    "    # Prints out all the project environment variables\n",
    "    # This is useful for debugging and seeing what is being set\n",
    "    for k, v in config.items():\n",
    "        # If ENV var starts with PROJECTNAME_ then print\n",
    "        if k.startswith(config[\"CORE_PROJECT_VARIABLE_PREFIX\"]):\n",
    "            print(f\"{k}={v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "show_project_env_vars(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_samplesheet\n",
    "This function is to unify the way we work with sample_sheet's which is for us a file with a table of values, typically samples for batch processing. We want to approach doing it this way so all programs have batch processing in mind and working with the same data structure.\n",
    "\n",
    "To make use of it we have a small sample_sheet yaml object which looks like\n",
    "    \n",
    "```yaml\n",
    "sample_sheet:\n",
    "    path: path/to/sample_sheet.tsv\n",
    "    delimiter: '\\t' # Optional, will assume , for csv and \\t otherwises\n",
    "    header: 0 # Optional, 0 indicates first row is header, None indicates no header\n",
    "    columns: ['column1', 'column2', 'column3'] # Optional, if not provided all columns will be used\n",
    "```\n",
    "\n",
    "Make sure to add that to your relevant section in your config (can be multiple times if you're working with different sheets or different columns), then call the function on this object and it'll either mention somethings wrong or return a pandas dataframe with the columns of interest.\n",
    "\n",
    "This is an example of a common sample_sheet we work with. We will ingest the hash at the beginning so it doesn't affect column naming. Extra empty rows at the end are also stripped.\n",
    "```tsv\n",
    "#sample_id\tfile_path\tmetadata1\tmetadata2\n",
    "Sample1\t/path/to/sample1.fasta\tvalue1\toption1\n",
    "Sample2\t/path/to/sample2.fasta\tvalue2\toption2\n",
    "Sample3\t/path/to/sample3.fasta\tvalue3\toption1\n",
    "Sample4\t/path/to/sample4.fasta\tvalue1\toption2\n",
    "Sample5\t/path/to/sample5.fasta\tvalue2\toption1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_samplesheet(sample_sheet_config: dict) -> pd.DataFrame:\n",
    "    # Load the sample sheet into a pandas dataframe\n",
    "    # If columns is not None then it will only load those columns\n",
    "    # If the sample sheet is a csv then it will load it as a csv, otherwise it will assume it's a tsv\n",
    "\n",
    "    # Expected sample_sheet_config:\n",
    "    # sample_sheet:\n",
    "    #   path: path/to/sample_sheet.tsv\n",
    "    #   delimiter: '\\t' # Optional, will assume , for csv and \\t otherwises\n",
    "    #   header: 0 # Optional, 0 indicates first row is header, None indicates no header\n",
    "    #   columns: ['column1', 'column2', 'column3'] # Optional, if not provided all columns will be used\n",
    "\n",
    "    # Example sample sheet:\n",
    "    # #sample_id\tfile_path\tmetadata1\tmetadata2\n",
    "    # Sample1\t/path/to/sample1.fasta\tvalue1\toption1\n",
    "    # Sample2\t/path/to/sample2.fasta\tvalue2\toption2\n",
    "    # Sample3\t/path/to/sample3.fasta\tvalue3\toption1\n",
    "    # Sample4\t/path/to/sample4.fasta\tvalue1\toption2\n",
    "    # Sample5\t/path/to/sample5.fasta\tvalue2\toption1\n",
    "\n",
    "    # This function should also handle ensuring the sample sheet is in the correct format, such as ensuring the columns are correct and that the sample names are unique.\n",
    "    if not os.path.isfile(sample_sheet_config[\"path\"]):\n",
    "        raise FileNotFoundError(f\"File {sample_sheet_config['path']} does not exist\")\n",
    "    if \"delimiter\" in sample_sheet_config:\n",
    "        delimiter = sample_sheet_config[\"delimiter\"]\n",
    "    else:\n",
    "        # do a best guess based on file extension\n",
    "        delimiter = \",\" if sample_sheet_config[\"path\"].endswith(\".csv\") else \"\\t\"\n",
    "    header = 0\n",
    "    # if \"header\" in sample_sheet_config:\n",
    "    #     header = sample_sheet_config[\"header\"]\n",
    "    # else:\n",
    "    #     # check if the first line starts with a #, if so lets assume it's a header otherwise assume there isn't one\n",
    "    #     with open(sample_sheet_config[\"path\"], \"r\") as f:\n",
    "    #         first_line = f.readline()\n",
    "    #         header = 0 if first_line.startswith(\"#\") else None\n",
    "    if \"columns\" in sample_sheet_config:\n",
    "        columns = sample_sheet_config[\n",
    "            \"columns\"\n",
    "        ]  # note the # for the first item needs to be stripped to compare to the columns\n",
    "    else:\n",
    "        columns = None  # implies all columns\n",
    "    try:\n",
    "        # note when we have a header the first column may begin with a #, so we need to remove it\n",
    "        df = pd.read_csv(\n",
    "            sample_sheet_config[\"path\"],\n",
    "            delimiter=delimiter,\n",
    "            header=header,\n",
    "            comment=None,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            \"Error: Could not load sample sheet into dataframe, you have a problem with your sample sheet or the configuration.\"\n",
    "        )\n",
    "        raise e\n",
    "\n",
    "    # Check the first header has a # in it, if so remove it for only that item\n",
    "    if df.columns[0].startswith(\"#\"):\n",
    "        df.columns = [col.lstrip(\"#\") for col in df.columns]\n",
    "    # Ensure the sample sheet has the correct columns\n",
    "    if columns is not None and not all([col in df.columns for col in columns]):\n",
    "        raise ValueError(\"Error: Sample sheet does not have the correct columns\")\n",
    "    # also drop columns which are not needed\n",
    "    if columns is not None:\n",
    "        df = df[columns]\n",
    "\n",
    "    # Clean the df of any extra rows that can be caused by empty lines in the sample sheet\n",
    "    df = df.dropna(how=\"all\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# This is included at the end to ensure when you run through your notebook the code is also transferred to the associated python package\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
